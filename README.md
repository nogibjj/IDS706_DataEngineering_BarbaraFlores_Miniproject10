[![Format](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Project1/actions/workflows/format.yml/badge.svg)](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject10/actions/workflows/format.yml)
[![Lint](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Project1/actions/workflows/lint.yml/badge.svg)](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject10/actions/workflows/lint.yml)
[![Install](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Project1/actions/workflows/install.yml/badge.svg)](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject10/actions/workflows/install.yml)
[![Test](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Project1/actions/workflows/test.yml/badge.svg)](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject10/actions/workflows/test.yml)



IDS706_DataEngineering_BarbaraFlores_Miniproject10
## ðŸ“‚ PySpark Data Processing

The goal of this miniproject is to leverage PySpark for efficient data processing. In Week 10, we focus on using PySpark to work with large datasets, incorporating Spark SQL queries and data transformations to meet the specified requirements. Explore the power of PySpark in this project as we dive into data processing with a focus on functionality, SQL integration, and the delivery of a PySpark script and a comprehensive output report.


### ðŸ“Š Database

For this project, we will utilize the [Top Spotify Songs in 73 Countries](https://www.kaggle.com/datasets/asaniczka/top-spotify-songs-in-73-countries-daily-updated/) dataset. This dataset provides a comprehensive view of the top songs trending in over 70 countries, offering valuable insights into the dynamics of the music industry. It includes a wide range of information on the most popular songs in the world, such as unique Spotify identifiers, song names, artists, daily rankings, daily movement in rankings, and more.

This dataset comprises 25 variables (columns) and was extracted on 2023-11-05. In total, it contains 72.959 records.


### ðŸ“¦ Data Processing with PySpark

In this project, we harness the power of PySpark for data processing on a large dataset. Using PySpark, we efficiently read the dataset and perform various data processing tasks, including Spark SQL queries and data transformations, to meet the specified requirements. The results of our analysis and processing will be saved in the "output" directory for further inspection and reference.

#### Using PySpark

We utilize PySpark, a fast and powerful data processing framework, to handle large-scale data efficiently. PySpark allows us to take advantage of distributed computing capabilities and perform complex data operations seamlessly. With its support for Spark SQL, we can easily query and analyze the dataset.

#### Output Data

The results of our data processing, which may include summary reports, will be saved in the "output" directory. You can find detailed reports, visualizations, or any other output data that provides insights into the dataset.

We hope to demonstrate the full potential of PySpark for efficient and effective data processing in this project. Stay tuned for further updates and insights.






